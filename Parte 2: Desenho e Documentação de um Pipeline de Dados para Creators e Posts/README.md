# Parte 2 - Arquitetura e Pipeline de Dados

Esta parte do projeto foca no **desenho e documentaÃ§Ã£o de um pipeline de dados escalÃ¡vel** para coleta e atualizaÃ§Ã£o contÃ­nua de informaÃ§Ãµes de criadores e posts.

## ğŸ¯ Objetivo
Criar uma soluÃ§Ã£o capaz de **ingestÃ£o, transformaÃ§Ã£o e disponibilizaÃ§Ã£o** de dados de forma automatizada, sem depender de arquivos JSON locais, mas conectando diretamente Ã s **APIs oficiais**.

## âš™ï¸ OrquestraÃ§Ã£o
O orquestrador escolhido Ã© o **Apache Airflow**, pela maturidade, escalabilidade e forte integraÃ§Ã£o com nuvens (AWS, GCP, Azure). Ele permite:
- Agendamento e monitoramento de DAGs;
- Retry automÃ¡tico em caso de falhas;
- SLA e alertas via e-mail/Slack.

## ğŸ—„ï¸ Modelagem de Dados
A modelagem Ã© organizada em **trÃªs camadas** no Data Lake:

- **Bronze:** dados crus vindos das APIs (sem tratamento).
- **Silver:** dados limpos e padronizados (chaves normalizadas).
- **Gold/Platinum:** dados analÃ­ticos para dashboards e data science.

As tabelas principais sÃ£o:
- `creators` â†’ informaÃ§Ãµes do criador.
- `posts` â†’ posts com mÃ©tricas de engajamento.
- `daily_engagement` â†’ histÃ³rico temporal de mÃ©tricas.

ğŸ‘‰ Mais detalhes em [`data_model.md`](./data_model.md).

## ğŸ“¤ ExtraÃ§Ã£o
- **Wikipedia API:** metadados dos criadores.
- **YouTube API:** estatÃ­sticas dos posts e canais.
- **AtualizaÃ§Ãµes contÃ­nuas:** rodando diariamente via Airflow, apenas novos registros ou atualizaÃ§Ãµes incrementais.

## ğŸ”„ Fluxo do Pipeline
1. **IngestÃ£o:** APIs â†’ Data Lake Bronze.  
2. **TransformaÃ§Ã£o:** Spark/Databricks â†’ tabelas Silver.  
3. **Curadoria:** enriquecimento + mÃ©tricas â†’ tabelas Gold.  
4. **Consumo:** BI (PowerBI/Looker) e modelos de machine learning.

## ğŸ“Š Monitoramento e Qualidade
- Logs e retries via Airflow.  
- ValidaÃ§Ã£o de dados com **Great Expectations** (ex.: campos obrigatÃ³rios, ranges esperados).  
- MÃ©tricas de completude e frescor monitoradas em dashboards de observabilidade.

## âœ… Boas PrÃ¡ticas
- Versionamento com **Gitflow**.  
- Testes unitÃ¡rios e integraÃ§Ã£o contÃ­nua (CI/CD).  
- Pipelines **idempotentes** (reprocessar sem duplicar dados).  
- Observabilidade e mÃ©tricas desde a ingestÃ£o atÃ© o consumo.
